{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from source.utils import set_random_seed, get_data\n",
    "set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./args/args.pkl','rb')\n",
    "args = pickle.load(f)\n",
    "f1 = open('./args/cifar_dytox.yaml', 'r', encoding='utf-8')\n",
    "args1 = yaml.safe_load(f1)\n",
    "f2 = open('./args/cifar100_order1.yaml', 'r', encoding='utf-8')\n",
    "args2 = yaml.safe_load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.update(args1)\n",
    "args.update(args2)\n",
    "args = edict(args)\n",
    "args.data_set = 'CIFAR'\n",
    "args.data_path = '/home/choiyj/pycil/data'\n",
    "args.output_basedir = ''\n",
    "args.distributed=False\n",
    "\n",
    "args.initial_increment = 0\n",
    "args.increment = 10\n",
    "incremental_classes = 10\n",
    "total_step = (100-args.initial_increment)//incremental_classes\n",
    "total_step = total_step if args.initial_increment==0 else total_step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from source.datasets import build_dataset\n",
    "scenario_train, args.nb_classes = build_dataset(is_train=True, args=args)\n",
    "scenario_val, _ = build_dataset(is_train=False, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ViT_exp import ViT_clf\n",
    "\n",
    "initial = 0\n",
    "total_steps = 10\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = ViT_clf(num_classes=10, img_size=32, patch_size=4, num_patches=64, \n",
    "                in_chans=3, embed_dim=384, depth=6, num_heads=args.num_heads, mlp_ratio=4.0, \n",
    "                qkv_bias=False, qk_scale=False, drop_rate=0., attn_drop_rate=0.0, drop_path=args.drop_path, norm_layer=nn.LayerNorm,\n",
    "                attention_type='GPSA')\n",
    "model.to(device)\n",
    "states = [torch.load(f'./weights/state_{i}_{initial}-{total_steps}steps.pt', map_location=device) for i in range(10)]\n",
    "tokens = [states[i]['task_tokens'] for i in range(10)]\n",
    "val_loaders = [get_data(i, args=args, scenario_train=scenario_train, scenario_val=scenario_val)[1] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ViT_exp import inference\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer = pd.DataFrame(np.full((10,10), np.nan))\n",
    "df_inner = pd.DataFrame(np.full((10,10), np.nan))\n",
    "\n",
    "model = ViT_clf(num_classes=10, img_size=32, patch_size=4, num_patches=64, \n",
    "                in_chans=3, embed_dim=384, depth=6, num_heads=args.num_heads, mlp_ratio=4.0, \n",
    "                qkv_bias=False, qk_scale=False, drop_rate=0., attn_drop_rate=0.0, drop_path=args.drop_path, norm_layer=nn.LayerNorm,\n",
    "                attention_type='GPSA')\n",
    "model.to(device)\n",
    "for task_id in range(10):\n",
    "    print(f'model{task_id}')\n",
    "    model.load_state_dict(states[task_id])\n",
    "    acc_inners = []\n",
    "    for task, loader in enumerate(val_loaders[:task_id+1]):\n",
    "        logits, targets = inference(model, loader, task, tokens[task], device)\n",
    "\n",
    "        acc_inner = accuracy_score(targets, logits.argmax(1) + task*10)\n",
    "        df_inner.iloc[task_id,task] = acc_inner\n",
    "        acc_inners.append(acc_inner)\n",
    "    print(np.mean(acc_inners))\n",
    "    if task_id == 0:\n",
    "        model.set_teacher_task_token(nn.Parameter(torch.zeros(1, 1, 384)))\n",
    "    model.classifier_expand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.873714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  \\\n",
       "0  0.926    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1  0.921  0.879    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2  0.923  0.870  0.859    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3  0.926  0.870  0.852  0.856    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4  0.923  0.867  0.849  0.866  0.885    NaN    NaN    NaN    NaN    NaN   \n",
       "5  0.926  0.866  0.850  0.865  0.882  0.920    NaN    NaN    NaN    NaN   \n",
       "6  0.925  0.863  0.850  0.860  0.884  0.915  0.819    NaN    NaN    NaN   \n",
       "7  0.919  0.856  0.841  0.853  0.882  0.918  0.822  0.905    NaN    NaN   \n",
       "8  0.919  0.858  0.845  0.852  0.875  0.913  0.817  0.902  0.892    NaN   \n",
       "9  0.920  0.847  0.841  0.838  0.874  0.907  0.825  0.895  0.891  0.853   \n",
       "\n",
       "    average  \n",
       "0  0.926000  \n",
       "1  0.900000  \n",
       "2  0.884000  \n",
       "3  0.876000  \n",
       "4  0.878000  \n",
       "5  0.884833  \n",
       "6  0.873714  \n",
       "7  0.874500  \n",
       "8  0.874778  \n",
       "9  0.869100  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inner['average'] = df_inner.mean(axis=1)\n",
    "df_inner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiclassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
